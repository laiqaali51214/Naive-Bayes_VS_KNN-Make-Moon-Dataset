# 🌙 Naïve Bayes vs KNN on Make Moon Dataset

## 📌 Project Overview
This project compares the performance of **Naïve Bayes** and **K-Nearest Neighbors (KNN)** classifiers on the **Make Moon Dataset**. The goal is to evaluate how these two algorithms perform on a non-linearly separable dataset.

## 📊 Dataset
The **Make Moon Dataset** is generated using the `make_moons` function from `sklearn.datasets`. It consists of two interleaving half-circle shapes, making it a good benchmark for classification models.

### 🔑 Key Features
- **Two classes (Binary Classification)**
- **Non-linearly separable dataset**
- **Used for benchmarking classification algorithms**


## 🚀 Usage
1. Open the Jupyter Notebook `Project10_Naïve Bayes_VS_KNN(Make Moon Dataset).ipynb`.
2. Run each cell to generate the dataset, train both models, and evaluate their performance.
3. The final output will include accuracy scores and decision boundary visualizations.

## 📈 Results
- **Naïve Bayes Accuracy:** X% (update with actual results)
- **KNN Accuracy:** Y% (update with actual results)
- **Decision Boundary Comparison:** Visualizes the strengths and weaknesses of each model.


---
👩‍💻 **Developed by:** Laiqa Ali

