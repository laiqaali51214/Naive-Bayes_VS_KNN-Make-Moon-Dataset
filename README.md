# ğŸŒ™ NaÃ¯ve Bayes vs KNN on Make Moon Dataset

## ğŸ“Œ Project Overview
This project compares the performance of **NaÃ¯ve Bayes** and **K-Nearest Neighbors (KNN)** classifiers on the **Make Moon Dataset**. The goal is to evaluate how these two algorithms perform on a non-linearly separable dataset.

## ğŸ“Š Dataset
The **Make Moon Dataset** is generated using the `make_moons` function from `sklearn.datasets`. It consists of two interleaving half-circle shapes, making it a good benchmark for classification models.

### ğŸ”‘ Key Features
- **Two classes (Binary Classification)**
- **Non-linearly separable dataset**
- **Used for benchmarking classification algorithms**


## ğŸš€ Usage
1. Open the Jupyter Notebook `Project10_NaÃ¯ve Bayes_VS_KNN(Make Moon Dataset).ipynb`.
2. Run each cell to generate the dataset, train both models, and evaluate their performance.
3. The final output will include accuracy scores and decision boundary visualizations.

## ğŸ“ˆ Results
- **NaÃ¯ve Bayes Accuracy:** X% (update with actual results)
- **KNN Accuracy:** Y% (update with actual results)
- **Decision Boundary Comparison:** Visualizes the strengths and weaknesses of each model.


---
ğŸ‘©â€ğŸ’» **Developed by:** Laiqa Ali

